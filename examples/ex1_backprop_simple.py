# -*- coding: utf-8 -*-
"""simple_backprop.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uUfs47Iu44AF57rtLPeKLjzpaseP0YIN
"""

#------------------------------------------------------------------------------
#NERS 590: Applied Machine Learning for Nuclear Engineers
#In-class sript: Backpropagation simple script (derivation given in the slides)
#Date: 8/10/2024
#Author: Majdi I. Radaideh
#-----------------------------------------------------------------------------
# look in the slides for how the derivatives were determined.

import numpy as np

# Sigmoid function and its derivative
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

# Inputs and outputs
x = np.array([0.5])  # Input
y_true = np.array([0.8])  # True output

# Initial weights and biases
w1 = np.array([0.1])
b1 = np.array([0.3])
w2 = np.array([0.4])
b2 = np.array([0.7])

# Learning rate
eta = 0.5

# Forward pass
z1 = w1 * x + b1
h1 = sigmoid(z1)

z2 = w2 * h1 + b2
y = sigmoid(z2)

# Compute loss (MSE)
loss = 0.5 * (y - y_true) ** 2

# Backward pass
dL_dy = y - y_true
dy_dz2 = sigmoid_derivative(y)

# Gradients for w2 and b2
dz2_dw2 = h1
dz2_db2 = 1

dL_dw2 = dL_dy * dy_dz2 * dz2_dw2
dL_db2 = dL_dy * dy_dz2 * dz2_db2

# Gradient for w1 and b1
dz2_dh1 = w2
dh1_dz1 = sigmoid_derivative(h1)
dz1_dw1 = x
dz1_db1 = 1

dL_dh1 = dL_dy * dy_dz2 * dz2_dh1
dL_dw1 = dL_dh1 * dh1_dz1 * dz1_dw1
dL_db1 = dL_dh1 * dh1_dz1 * dz1_db1

# Update weights and biases
w1 -= eta * dL_dw1
b1 -= eta * dL_db1
w2 -= eta * dL_dw2
b2 -= eta * dL_db2

print("Updated weights and biases:")
print("w1:", w1)
print("b1:", b1)
print("w2:", w2)
print("b2:", b2)